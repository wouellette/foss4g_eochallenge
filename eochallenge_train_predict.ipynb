{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# General imports\n",
    "import glob\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import random\n",
    "from enum import Enum\n",
    "import datetime\n",
    "from functools import partial\n",
    "from multiprocess import Pool\n",
    "\n",
    "from tqdm import tqdm\n",
    "import easydict\n",
    "\n",
    "# Interactive multithreading\n",
    "from nbmultitask import ThreadWithLogAndControls\n",
    "from time import sleep\n",
    "\n",
    "# Imports relative to web mapping and displaying results\n",
    "from ipyleaflet import Map, basemaps, ImageOverlay, TileLayer, GeoData\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as anim\n",
    "from sidecar import Sidecar\n",
    "\n",
    "\n",
    "# Array processing libraries\n",
    "import numpy as np\n",
    "from numpy import unravel_index\n",
    "import rasterio as rio\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.io import MemoryFile\n",
    "\n",
    "# Geospatial data wrangling (mostly vector data)\n",
    "import utm\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon,MultiPoint\n",
    "\n",
    "# EO-learn/Sentinelhub imports\n",
    "from eolearn.core import (\n",
    "    EOWorkflow,\n",
    "    Dependency,\n",
    "    EOPatch,\n",
    "    LoadFromDisk,\n",
    "    SaveToDisk,\n",
    "    OverwritePermission,\n",
    "    FeatureType,\n",
    "    LinearWorkflow,\n",
    "    EOTask)\n",
    "from eolearn.features import LinearInterpolation, SimpleFilterTask\n",
    "from eolearn.geometry import PointSamplingTask, VectorToRaster\n",
    "from eolearn.io import ExportToTiff, SentinelHubWCSInput, S2L1CWCSInput\n",
    "from eolearn.mask import AddValidDataMaskTask, get_s2_pixel_cloud_detector, AddCloudMaskTask\n",
    "from eolearn.ml_tools import MorphologicalOperations, MorphologicalStructFactory\n",
    "from sentinelhub import CRS, BBoxSplitter, WcsRequest, DataSource, CustomUrlParam\n",
    "from sentinelhub.constants import MimeType\n",
    "\n",
    "# ML libraries\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import joblib\n",
    "\n",
    "from eochallenge_prepare_data import (\n",
    "    load_eopatch, \n",
    "    interpolate_eopatch, \n",
    "    intersect_aoi, \n",
    "    args, \n",
    "    train_model, \n",
    "    predict_eopatch, \n",
    "    plot_confusion_matrix\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# The AOI should be in EPSG:4326\n",
    "out_path = args.dest\n",
    "bufsize = args.aoi_bufsize\n",
    "row = args.zoom_level[0]\n",
    "col = args.zoom_level[1]\n",
    "\n",
    "aoi = gpd.read_file(args.aoi)\n",
    "aoi['geometry'] = aoi['geometry'].to_crs(epsg=3857).buffer(bufsize).to_crs(epsg=4326)\n",
    "\n",
    "country_list = ['Germany','Romania']\n",
    "bbox_splitter_list = []\n",
    "gdfs = [] # an array of GeoDataFrames to be plotted later\n",
    "# Assuming there are two AOIs: one for Romania, one for Germany\n",
    "for idx, aoi_el in zip(country_list, aoi.geometry):\n",
    "\n",
    "    aoi_latlon = aoi_el.centroid.coords[0]\n",
    "    utm_crs = utm.from_latlon(aoi_latlon[1], aoi_latlon[0])\n",
    "    if aoi_latlon[1] > 0:\n",
    "        if utm_crs[2] > 9:\n",
    "            aoi_crs = 'EPSG:326%s' % utm_crs[2]\n",
    "        else:\n",
    "            aoi_crs = 'EPSG:3260%s' % utm_crs[2]\n",
    "    else:\n",
    "        if utm_crs[2] > 9:\n",
    "            aoi_crs = 'EPSG:327%s' % utm_crs[2]\n",
    "        else:\n",
    "            aoi_crs = 'EPSG:3270%s' % utm_crs[2]\n",
    "\n",
    "    # Split the AOI into a processing grid matching the OSM zoom level 12 grid\n",
    "\n",
    "    aoi_temp = aoi['geometry'].to_crs(aoi_crs)\n",
    "\n",
    "    print(country_list.index(idx))\n",
    "    bbox_splitter = BBoxSplitter([aoi_temp[country_list.index(idx)]], aoi_crs, (row, col))\n",
    "    bbox_splitter_list.append(bbox_splitter)\n",
    "\n",
    "    bbox_list = bbox_splitter.get_bbox_list()\n",
    "    print('Area bounding box: {}\\n'.format(bbox_splitter.get_area_bbox().__repr__()))\n",
    "    print('Each bounding box also has some info how it was created. Example:'\n",
    "          '\\nbbox: {}\\ninfo: {}\\n'.format(bbox_list[0].__repr__(), bbox_splitter.info_list[0]))\n",
    "    print(f'\\nThe AOI is covered by {len(bbox_splitter.bbox_list)} tiles to be processed.')\n",
    "\n",
    "    # Create the path where to store the split processing grid.\n",
    "    os.makedirs(f'{out_path}/aoi', exist_ok=True)\n",
    "\n",
    "    with open(f'{out_path}/aoi/aoi_bbox_4326_{idx}_r{row}_c{col}.pkl', 'wb') as f:\n",
    "        pickle.dump(bbox_splitter, f)\n",
    "\n",
    "    geometry = [Polygon(bbox.get_polygon()) for bbox in bbox_list]\n",
    "    idxs_x = [info['index_x'] for info in bbox_splitter.info_list]\n",
    "    idxs_y = [info['index_y'] for info in bbox_splitter.info_list]\n",
    "\n",
    "    df = pd.DataFrame({'index_x': idxs_x, 'index_y': idxs_y})\n",
    "    gdf = gpd.GeoDataFrame(df, crs={'init': CRS.ogc_string(bbox_list[0].crs)}, geometry=geometry)\n",
    "    gdf.head()\n",
    "\n",
    "    gdf.to_file(f'{out_path}/aoi/aoi_bbox_4326_{idx}_r{row}_c{col}_{len(bbox_splitter.bbox_list)}.shp')\n",
    "    gdfs.append(gdf)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "for aoi_idx, bbox_splitter in enumerate(bbox_splitter_list):\n",
    "    if aoi_idx == 0:\n",
    "        range_bbox = intersect_aoi(bbox_splitter, trainings[aoi_idx])\n",
    "        range_idx = [bbox_splitter.bbox_list.index(bbox) for bbox in range_bbox]\n",
    "        model, range_sample, labels_unique = train_model(range_idx, args.lulc_classes, args.time_range, out_path=f'{out_path}/{country_list[aoi_idx]}')\n",
    "        for idx in [bbox_splitter.bbox_list.index(bbox) for bbox in bbox_splitter.bbox_list]:\n",
    "            load_eopatch(bbox_splitter, time_range, training_arrays[aoi_idx],\n",
    "            split_arrays[aoi_idx], training_vals[aoi_idx], f'{out_path}/{country_list[aoi_idx]}', row, col, idx)\n",
    "            interpolate_eopatch(resample_range, training_vals[aoi_idx], f'{out_path}/{country_list[aoi_idx]}', idx)\n",
    "            predict_eopatch(model, bbox_splitter, labels_unique,\n",
    "                            args.proba, args.shap, f'{out_path}/{country_list[aoi_idx]}', idx)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(20,20))\n",
    "\n",
    "class_names_test = [class_names[label] for label in np.unique(labels_test)]\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "conf_matrix_gbm = metrics.confusion_matrix(labels_test, plabels_test)\n",
    "plot_confusion_matrix(conf_matrix_gbm,\n",
    "                      classes=class_names_test,\n",
    "                      normalize=True,\n",
    "                      ylabel='Truth (RABA)',\n",
    "                      xlabel='Predicted (GBM)',\n",
    "                      title='Confusion matrix')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "conf_matrix_gbm = metrics.confusion_matrix(plabels_test, labels_test)\n",
    "plot_confusion_matrix(conf_matrix_gbm,\n",
    "                      classes=class_names_test,\n",
    "                      normalize=True,\n",
    "                      xlabel='Truth (RABA)',\n",
    "                      ylabel='Predicted (GBM)',\n",
    "                      title='Transposed Confusion matrix')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "\n",
    "fig2 = plt.figure(figsize=(20,5))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Training Data Distribution Across Classes\n",
    "label_ids, label_counts = np.unique(labels_train, return_counts=True)\n",
    "\n",
    "plt.barh(range(len(label_ids)),label_counts)\n",
    "plt.yticks(range(len(label_ids)), [class_names[i] for i in label_ids], fontsize=20)\n",
    "plt.xticks(fontsize=20, rotation=45)\n",
    "plt.title(f'Training Data Abundance Distribution across classes', fontsize=16, y=1.2)\n",
    "plt.suptitle(f'Total sample size: {np.sum(label_counts)}',fontsize=14)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Plot ROC Curve\n",
    "\n",
    "#Calculate precision and recall rates.\n",
    "class_labels = np.unique(np.hstack([labels_test,labels_train]))\n",
    "print(class_names)\n",
    "\n",
    "scores_test = model.predict_proba(features_test)\n",
    "labels_binarized = preprocessing.label_binarize(labels_test, classes=class_labels)\n",
    "plot_colors = ['xkcd:darkgreen', 'xkcd:lime','xkcd:tan', 'orange','xkcd:beige','crimson','xkcd:azure', 'xkcd:lavender','xkcd:lightblue'] #'white','xkcd:lavender', 'black'\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for idx,lbl in enumerate(class_labels):\n",
    "    fpr[idx], tpr[idx], _ = metrics.roc_curve(labels_binarized[:, idx], scores_test[:, idx])\n",
    "    roc_auc[idx] = metrics.auc(fpr[idx], tpr[idx])\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "absent_value = []\n",
    "for idx,lbl in enumerate(class_labels):\n",
    "    if np.isnan(roc_auc[idx]):\n",
    "        continue\n",
    "    try:\n",
    "        plt.plot(fpr[idx], tpr[idx], color=plot_colors[idx],lw=2, label=class_names[lbl]+' (%0.5f)' % roc_auc[idx])\n",
    "    except:\n",
    "        absent_value.append(lbl)\n",
    "        continue\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 0.2])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize=20)\n",
    "plt.ylabel('True Positive Rate', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.title(f'Receiver operating characteristic for {project_name}', fontsize=20)\n",
    "plt.legend(loc=\"lower right\", prop={'size':15})\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Plot Feature Importance\n",
    "\n",
    "# names of features\n",
    "fnames = ['B2','B3','B4','B8','B11','B12','NDVI','NDWI','NORM']\n",
    "\n",
    "# get feature importances and reshape them to dates and features\n",
    "z = np.zeros(t1*f1)\n",
    "z = model.feature_importances_\n",
    "z = z.reshape((t1,f1))\n",
    "\n",
    "fig3 = plt.figure(figsize=(20,18))\n",
    "ax = plt.gca()\n",
    "\n",
    "# plot the importances\n",
    "im = ax.imshow(z,aspect=0.5)\n",
    "plt.xticks(range(len(fnames)), fnames, rotation = 45, fontsize=20)\n",
    "plt.yticks(range(t1), ['T{}'.format(i) for i in range(t1)], fontsize=20)\n",
    "\n",
    "cax = fig3.add_axes([0.82, 0.125, 0.04, 0.755])\n",
    "plt.colorbar(im, cax=cax)\n",
    "plt.title(f'feature importance per date for {project_name}', fontsize=20, x=-7)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Plot most important band/date combination\n",
    "\n",
    "z_max = unravel_index(np.argmax(z), z.shape)\n",
    "print(z_max)\n",
    "z_min = unravel_index(np.argmin(z[z>0]), z.shape)\n",
    "print(z_min)\n",
    "\n",
    "bsub_tsub = np.swapaxes(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[range_sample]]), 1, 3)[...,z_min[0],z_min[1]].reshape(p1*h1*w1)\n",
    "bopt_tsub = np.swapaxes(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[range_sample]]), 1, 3)[...,z_max[0],z_min[1]].reshape(p1*h1*w1)\n",
    "bsub_topt = np.swapaxes(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[range_sample]]), 1, 3)[...,z_min[0],z_max[1]].reshape(p1*h1*w1)\n",
    "bopt_topt = np.swapaxes(np.array([eopatch.data['FEATURES_SAMPLED'] for eopatch in eopatches[range_sample]]), 1, 3)[...,z_max[0],z_max[1]].reshape(p1*h1*w1)\n",
    "labels = np.array([eopatch.mask_timeless['LULC_SAMPLED'] for eopatch in eopatches[range_sample]]).reshape(p1*h1*w1*1)\n",
    "\n",
    "# remove nans\n",
    "mask = np.any([np.isnan(bsub_tsub), np.isnan(bopt_tsub), np.isnan(bsub_topt), np.isnan(bopt_topt), labels==0],axis=0)\n",
    "bsub_tsub, bopt_tsub, bsub_topt, bopt_topt, labels = [array[~mask] for array in [bsub_tsub, bopt_tsub, bsub_topt, bopt_topt, labels]]\n",
    "\n",
    "fig4 = plt.figure(figsize=(20,20))\n",
    "\n",
    "plot_labels = np.unique(labels)\n",
    "plot_colors = lulc_cmap.colors\n",
    "plot_colors = ['xkcd:darkgreen', 'xkcd:lime','xkcd:tan', 'orange','xkcd:beige','crimson','xkcd:azure', 'xkcd:lavender','xkcd:lightblue'] #'white','xkcd:lavender', 'black'\n",
    "print(plot_labels)\n",
    "print(plot_colors)\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist([bsub_topt[labels == i] for i in plot_labels],100,(-0.4, 0.8),histtype='step',\n",
    "         color=[plot_colors[i] for i in range(len(plot_labels))],\n",
    "         label=[class_names[i] for i in plot_labels],\n",
    "         )\n",
    "plt.title(f'Most important band at least optimal date T{z_min[0]}', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(f'{fnames[z_max[1]]}', fontsize=20)\n",
    "plt.legend(loc=1, prop={'size':15})\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist([bopt_topt[labels == i] for i in plot_labels],100,(-0.4, 0.8),histtype='step',\n",
    "         color=[plot_colors[i] for i in range(len(plot_labels))],\n",
    "         )\n",
    "plt.title(f'Most important band at most optimal date T{z_max[0]}', fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(f'{fnames[z_max[1]]}', fontsize=20)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title(f'Least important band at least optimal date T{z_min[0]}', fontsize=20)\n",
    "plt.hist([bsub_tsub[labels == i] for i in plot_labels],100,(0.1, 0.7),histtype='step',\n",
    "         color=[plot_colors[i] for i in range(len(plot_labels))],\n",
    "         )\n",
    "plt.xticks(fontsize=20)#     plt.yticks(fontsize=20)\n",
    "plt.xlabel(f'{fnames[z_min[1]]}', fontsize=20)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title(f'Least important band at most optimal date T{z_max[0]}', fontsize=20)\n",
    "plt.hist([bopt_tsub[labels == i] for i in plot_labels],100,(0.1, 0.7),histtype='step',\n",
    "         color=[plot_colors[i] for i in range(len(plot_labels))],\n",
    "         )\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(f'{fnames[z_min[1]]}', fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "pbar = tqdm(total=len(bbox_splitter.bbox_list))\n",
    "\n",
    "\n",
    "# # Predict EOPatches using trained model\n",
    "#\n",
    "\n",
    "# # Plot a web map\n",
    "# Some examples of implementation using ipywidget and ipyleaflet.\n",
    "#\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Color mapping of the land cover classes to display.\n",
    "newcolors = np.zeros((12,4))\n",
    "newcolors[0,:] = np.asarray([0,0,0,0])\n",
    "newcolors[1,:] = np.asarray([183, 219, 177, 255])\n",
    "newcolors[2,:] = np.asarray([0,0,0,0])\n",
    "newcolors[3,:] = np.asarray([149, 224, 145, 255])\n",
    "newcolors[4,:] = np.asarray([255, 223, 145, 255])\n",
    "newcolors[5,:] = np.asarray([0,0,0,0])\n",
    "newcolors[6,:] = np.asarray([226, 193, 115, 255])\n",
    "newcolors[7,:] = np.asarray([255, 244, 150, 255])\n",
    "newcolors[8,:] = np.asarray([255, 150, 150, 255])\n",
    "newcolors[9,:] = np.asarray([150, 171, 255, 255])\n",
    "newcolors[10,:] = np.asarray([209, 183, 255, 255])\n",
    "newcolors[11,:] = np.asarray([183, 255, 253, 255])\n",
    "\n",
    "print(newcolors/255)\n",
    "newcmp = ListedColormap(newcolors/255)\n",
    "print(newcmp)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Create a map using Stamen Terrain, centered on study area with set zoom level\n",
    "m = Map(center=(37, -120), zoom=0, basemap=basemaps.Stamen.Toner)\n",
    "m\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "sc = Sidecar(title='California Map')\n",
    "with sc:\n",
    "    display(m)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "# Iteratively display the predicted tiles as they become available in folder structure\n",
    "for tiff in glob.glob(\"/mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/val_pred_sh_eopatch_*local.tiff\"):\n",
    "    out_path = \"/mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/folium/\"+tiff[:-5].split('/')[-1]+\"_4326.tiff\"\n",
    "    with rio.open(out_path) as src:\n",
    "       boundary = src.bounds\n",
    "\n",
    "    m.add_layer(ImageOverlay(url=\"http://172.29.254.183:8000/\"+tiff[:-5].split('/')[-1]+\"_4326.png\", bounds=((boundary[1], boundary[0]),\n",
    "                                            (boundary[3], boundary[2])), opacity=1))\n",
    "    m\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#Add a local tile server\n",
    "os.chdir(\"/mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/\")\n",
    "m.add_layer(TileLayer(url=\"http://172.29.254.183:8000/{z}/{x}/{y}.png\"))\n",
    "m\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "for tiff in glob.glob(\"/mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/val_pred_sh_eopatch_*local.tiff\"):\n",
    "    # Create variables for destination coordinate system and the name of the projected raster\n",
    "    src_crs = 'EPSG:32719'\n",
    "    dst_crs = 'EPSG:4326'\n",
    "    out_vrt = \"/mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/folium/\"+tiff[:-5].split('/')[-1]+\"_col1.tiff\"\n",
    "    out_vrt1 = \"/mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/folium/\"+tiff[:-5].split('/')[-1]+\"_col.tiff\"\n",
    "    out_path = \"/mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/folium/\"+tiff[:-5].split('/')[-1]+\"_4326.tiff\"\n",
    "    out_jpg = \"/mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/folium/\"+tiff[:-5].split('/')[-1]+\"_4326.png\"\n",
    "    out_tms = \"/mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/folium/\"+tiff[:-5].split('/')[-1]+\"_4326\"\n",
    "    #print(out_path)\n",
    "\n",
    "    cmd = 'gdaldem color-relief %s /mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/col.txt %s -of Gtiff'%(tiff,out_vrt)\n",
    "    get_ipython().system('{cmd}')\n",
    "    \"\"\"cmd1 = 'gdalwarp -of GTiff -overwrite -s_srs %s -t_srs %s %s %s'%(src_crs, dst_crs, out_vrt, out_vrt1)\n",
    "    !{cmd1}\n",
    "    os.remove(out_vrt)\n",
    "    cmd2 = 'gdal_translate -of JPEG %s %s'%(out_vrt1,out_path)\n",
    "    !{cmd2}\"\"\"\n",
    "\n",
    "    #subprocess.call([\"gdaldem\",\"color-relief\", tiff, \"/mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/col.txt\",out_vrt,\"-of\" ,\"VRT\"])\n",
    "    #subprocess.call([\"gdalwarp\",\"-of\", \"JPEG\", \"-s_srs\",src_crs,\"-t_srs\",dst_crs, out_vrt, out_path])\n",
    "\n",
    "    # Use rasterio package as rio to open and project the raster\n",
    "    with rio.open(out_vrt) as src:\n",
    "        transform, width, height = calculate_default_transform(\n",
    "            src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "        kwargs = src.meta.copy()\n",
    "        kwargs.update({\n",
    "            'crs': dst_crs,\n",
    "            'transform': transform,\n",
    "            'width': width,\n",
    "            'height': height\n",
    "        })\n",
    "\n",
    "        # Use rasterio package as rio to write out the new projected raster\n",
    "        # Code uses loop to account for multi-band rasters\n",
    "        with rio.open(out_path, 'w', **kwargs) as dst:\n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                source=rio.band(src, i),\n",
    "                destination=rio.band(dst, i),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=dst_crs,\n",
    "                resampling=Resampling.nearest)\n",
    "    # Use rasterio to import the reprojected data as img\n",
    "    with rio.open(out_path) as src:\n",
    "        boundary = src.bounds\n",
    "        #print(boundary)\n",
    "        #img = src.read()\n",
    "        #nodata = src.nodata\n",
    "\n",
    "    cmd2 = \"convert %s -transparent black -fuzz 11%% %s\"%(out_path, out_jpg)\n",
    "    get_ipython().system('{cmd2}')\n",
    "\n",
    "    # Overlay raster called img using add_child() function (opacity and bounding box set)\n",
    "    #m.add_child( folium.raster_layers.ImageOverlay(img[0], opacity=1, colormap=newcmp,\n",
    "    #                                 bounds =[[boundary[1], boundary[0]], [boundary[3], boundary[2]]]))\n",
    "    m.add_layer(ImageOverlay(url=\"http://172.29.254.183:8000/\"+tiff[:-5].split('/')[-1]+\"_4326.png\", bounds=((boundary[1], boundary[0]),\n",
    "                                             (boundary[3], boundary[2])), opacity=1))\n",
    "\n",
    "    m\n",
    "\n",
    "m.save(outfile= \"/mnt/1t-drive/eopatch-L1C/nam_usa_uca/lulc_pred/folium/test.html\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}